var documenterSearchIndex = {"docs":
[{"location":"functionindex/#Index","page":"functionindex","title":"Index","text":"","category":"section"},{"location":"functionindex/","page":"functionindex","title":"functionindex","text":"Modules = [RogueLearning]","category":"page"},{"location":"#RogueLearning.jl","page":"Home","title":"RogueLearning.jl","text":"","category":"section"},{"location":"#Layers","page":"Home","title":"Layers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"GenDense","category":"page"},{"location":"#RogueLearning.GenDense","page":"Home","title":"RogueLearning.GenDense","text":"Generalized version of Flux's Dense layer. \n\nGenDense(in=>out, σ=identity; \n         ω = identity, ψ = *, init = glorot_uniform, \n         bias=true, γ=Flux.Zeros()\n\nCan also be initialized with an additional set of trainable weights \n\nGenDense(in=>out, in_asym=>out_asym, σ = identity; \n         ω = identity, ψ = *, init = glorot_uniform, \n         bias=true, bias_asym=true, γ=Flux.Zeros())\n\n\n\n\n\n","category":"type"},{"location":"","page":"Home","title":"Home","text":"GenConv","category":"page"},{"location":"#RogueLearning.GenConv","page":"Home","title":"RogueLearning.GenConv","text":"Generalized version of Flux's conv layer\n\n\n\n\n\n","category":"type"},{"location":"#Similarity/correlation-functions","page":"Home","title":"Similarity/correlation functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"matmul","category":"page"},{"location":"#RogueLearning.matmul","page":"Home","title":"RogueLearning.matmul","text":"Regular matrix multiplication.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"matmul_asym_∂x","category":"page"},{"location":"#RogueLearning.matmul_asym_∂x","page":"Home","title":"RogueLearning.matmul_asym_∂x","text":"Compute matrix multiplication, but takes an additional matrix B as input.  B has same dims as Wᵀ, and is used in the backwards pass.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"matmul_blocked_∂x","category":"page"},{"location":"#RogueLearning.matmul_blocked_∂x","page":"Home","title":"RogueLearning.matmul_blocked_∂x","text":"Matrix multiplication with custom rrule\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"radialSim","category":"page"},{"location":"#RogueLearning.radialSim","page":"Home","title":"RogueLearning.radialSim","text":"Compute negative squared euclidean distance D between the rows of matrix W and the columns of matrix X. Denoting the rows of W by index i and the columns of X by index j the elements of the output matrix is given by: Dᵢⱼ = -||Wᵢ﹕ - X﹕ⱼ||² = 2Wᵢ﹕X﹕,j - ||Wᵢ﹕||^2 - ||X﹕ⱼ||².\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"radialSim_asym","category":"page"},{"location":"#RogueLearning.radialSim_asym","page":"Home","title":"RogueLearning.radialSim_asym","text":"In the forward pass this function behaves just like radialSim, but in the backwards pass weight symmetry is broken by using matrix B rather than Wᵀ. See docstring for radialSim for more details.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Home","title":"Home","text":"conv_asym_∂x","category":"page"},{"location":"#RogueLearning.conv_asym_∂x","page":"Home","title":"RogueLearning.conv_asym_∂x","text":"computes the convolution of image x with kernel w when called, but uses a different set of weights w_asym to compute the pullback wrt x. This is typically uses in feedback alignment experiments.\n\n\n\n\n\n","category":"function"},{"location":"#Loss-functions","page":"Home","title":"Loss functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"direct_feedback_loss","category":"page"},{"location":"#RogueLearning.direct_feedback_loss","page":"Home","title":"RogueLearning.direct_feedback_loss","text":"Error function which takes a vector of the hidden and output neurons states as well as a vector of feedback matrices as arguments\n\n\n\n\n\n","category":"function"},{"location":"#Activation-functions","page":"Home","title":"Activation functions","text":"","category":"section"}]
}
